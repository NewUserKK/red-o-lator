* each SIMD has:
    - its own PC
    - instruction buffer for 10 wavefronts
* Wavefront has:

* Cluster of 4 CU:
    - share 32KB L1 instruction cache that is 4-way associative and backed by the L2 cache. Cache lines are 64B long
                                                                                            and typically hold 8 instructions. When the cache is full, a new request will evict the Least Recently Used (i.e. LRU replacement) cache line to make room for
                                                                                            new instructions. The shared L1 instruction cache has 4 banks, and can sustain 32B instruction fetch per cycle to all 4 Compute Units. Instruction fetching is
                                                                                            arbitrated between SIMDs within a CU based on age, scheduling priority and utilization of the wavefront instruction buffers.
    -  L1 data cache is a read only structure ?????? The 16KB scalar data L1 is 4-way associative with 64B lines and LRU replacement; it is
                                                         also shared between a cluster of up to 4 Compute Units and backed by the L2 cache.
                                                         . It has 4 banks, with a throughput of 16B/cycle for each of the 4 Compute Units. The scalar data L1 cache replaces the constant cache in previous generations, as
                                                         it is significantly more flexible.
* each CU has:
    - 16 buffers to track barrier instructions, which force a wavefront to synchronize globally
    - 8KB scalar register file that is divided into 512 entries for each SIMD

